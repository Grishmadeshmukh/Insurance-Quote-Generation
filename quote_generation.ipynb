{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sqlalchemy pyodbc pandas numpy torch matplotlib pillow azure-storage-blob azure-identity\n",
    "# !pip install pymssql torchvision scikit-learn\n",
    "# !pip uninstall -y pyarrow\n",
    "# !pip install pyarrow\n",
    "# !pip install fastparquet  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "from sqlalchemy import create_engine, text\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pymssql\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import pickle\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import pyarrow\n",
    "import fastparquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Database connection ready\n",
      " Azure Blob Storage client ready\n"
     ]
    }
   ],
   "source": [
    "# Database Configuration\n",
    "SERVER = \"server\"\n",
    "DATABASE = \"db\"\n",
    "USERNAME = \"username\"\n",
    "PASSWORD = \"password\"\n",
    "\n",
    "STORAGE_ACCOUNT_NAME = \"account\"  \n",
    "STORAGE_ACCOUNT_KEY = \"key+ASt7cDLtQ==\"  \n",
    "\n",
    "CONTAINER_NAME_IMAGES = \"container\"  # Container name for CT scan images\n",
    "CONTAINER_NAME_DATA = \"container\"    # Container name for data files (parquet)\n",
    "\n",
    "PARQUET_BLOB_PATH = \"city_wellness_curated.parquet\"  \n",
    "MEDICAL_IMAGES_PREFIX = \"medical_images/\"  \n",
    "\n",
    "MODEL_DIR = 'Database/models'\n",
    "\n",
    "def get_connection():\n",
    "    return pymssql.connect(\n",
    "        server=SERVER,\n",
    "        user=USERNAME,\n",
    "        password=PASSWORD,\n",
    "        database=DATABASE,\n",
    "        port=1433,\n",
    "        tds_version=\"7.4\"\n",
    "    )\n",
    "\n",
    "def get_blob_service_client():\n",
    "    try:\n",
    "        connection_string = f\"DefaultEndpointsProtocol=https;AccountName={STORAGE_ACCOUNT_NAME};AccountKey={STORAGE_ACCOUNT_KEY};EndpointSuffix=core.windows.net\"\n",
    "        blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "        return blob_service_client\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not initialize blob service client: {e}\")\n",
    "        print(\"Make sure to update STORAGE_ACCOUNT_NAME and STORAGE_ACCOUNT_KEY\")\n",
    "        return None\n",
    "\n",
    "blob_service_client = get_blob_service_client()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Database Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Database helper functions ready\n"
     ]
    }
   ],
   "source": [
    "def get_customer(customer_id):\n",
    "    conn = get_connection()\n",
    "    cursor = conn.cursor(as_dict=True)\n",
    "    cursor.execute(\"SELECT * FROM Customer WHERE CustomerID = %s\", (customer_id,))\n",
    "    row = cursor.fetchone()\n",
    "    conn.close()\n",
    "    return row\n",
    "\n",
    "def get_health_factors(customer_id):\n",
    "    conn = get_connection()\n",
    "    cursor = conn.cursor(as_dict=True)\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT FactorName, FactorValue\n",
    "        FROM CustomerHealthFactor\n",
    "        WHERE CustomerID = %s\n",
    "    \"\"\", (customer_id,))\n",
    "    rows = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return rows\n",
    "\n",
    "def insert_health_factor(customer_id, factor_name, factor_value, year=2024, asset_id=1):\n",
    "    conn = get_connection()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO CustomerHealthFactor (CustomerID, FactorName, FactorValue, FactorYear, SourceAssetID)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\", (customer_id, factor_name, factor_value, year, asset_id))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def get_customer_image_blob(customer_id):\n",
    "    conn = get_connection()\n",
    "    cursor = conn.cursor(as_dict=True)\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT TOP 1 ImageFileName \n",
    "        FROM CustomerHealthFactor \n",
    "        WHERE CustomerID = %s AND ImageFileName IS NOT NULL\n",
    "        ORDER BY FactorID DESC\n",
    "    \"\"\", (customer_id,))\n",
    "    row = cursor.fetchone()\n",
    "    conn.close()\n",
    "    return row[\"ImageFileName\"] if row and \"ImageFileName\" in row else None\n",
    "\n",
    "def insert_contract(customer_id):\n",
    "    conn = get_connection()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO Contract (AccountID, CompanyCode, OwnerCustomerID, PayerCustomerID,\n",
    "                              PolicyNumber, IssueDate, Status)\n",
    "        VALUES (1, 'NY', %s, %s, CONCAT('POL', FLOOR(RAND()*1000000)), GETDATE(), 'Pending')\n",
    "    \"\"\", (customer_id, customer_id))\n",
    "    conn.commit()\n",
    "    cursor.execute(\"SELECT @@IDENTITY AS ContractID\")\n",
    "    contract_id = cursor.fetchone()[0]\n",
    "    conn.close()\n",
    "    return contract_id\n",
    "\n",
    "def insert_contract_benefit(contract_id, benefit_type=\"Health\", coverage_amount=50000.00):\n",
    "    conn = get_connection()\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        # Based on actual schema: ContractBenefitID, ContractID, BenefitType, CoverageAmount, EffectiveDate, EndDate\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO ContractBenefit (ContractID, BenefitType, CoverageAmount, EffectiveDate, EndDate)\n",
    "            VALUES (%s, %s, %s, GETDATE(), DATEADD(YEAR, 2, GETDATE()))\n",
    "        \"\"\", (contract_id, benefit_type, coverage_amount))\n",
    "        conn.commit()\n",
    "        cursor.execute(\"SELECT @@IDENTITY AS ContractBenefitID\")\n",
    "        contract_benefit_id = cursor.fetchone()[0]\n",
    "        conn.close()\n",
    "        return contract_benefit_id\n",
    "    except Exception as e:\n",
    "        conn.close()\n",
    "        raise ValueError(f\"Could not insert ContractBenefit: {e}\")\n",
    "\n",
    "def insert_contract_premium(contract_benefit_id, premium):\n",
    "    conn = get_connection()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO ContractPremium (ContractBenefitID, WritingAssociateID, PremiumAmount,\n",
    "                                     Frequency, EffectiveDate)\n",
    "        VALUES (%s, 1, %s, 'Monthly', GETDATE())\n",
    "    \"\"\", (contract_benefit_id, premium))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def refresh_materialized_views():\n",
    "    conn = get_connection()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"EXEC Refresh_Materialized_Views\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "print(\" Database helper functions ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load ML Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      " Loaded CT model from /Users/grishmadeshmukh/Desktop/NYUMasters/Sem3/Database/part4/models/ct_risk_model.pth\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "#  ResNet18\n",
    "ct_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def load_ct_model(model_path):\n",
    "    model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(model.fc.in_features, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "    if model_path and os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        print(f\"Loaded CT model from {model_path}\")\n",
    "    else:\n",
    "        print(\"Warning: Using ImageNet-initialized CT model. Train and save model first.\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Load CT model\n",
    "ct_model = load_ct_model(os.path.join(MODEL_DIR, 'ct_risk_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded wellness model from /Users/grishmadeshmukh/Desktop/NYUMasters/Sem3/Database/part4/models/wellness_model.pth\n",
      " Loaded scaler from /Users/grishmadeshmukh/Desktop/NYUMasters/Sem3/Database/part4/models/wellness_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "class WellnessNN(nn.Module):\n",
    "    def __init__(self, input_size=9):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def load_wellness_model(model_path, scaler_path, input_size=9):\n",
    "    model = WellnessNN(input_size=input_size)\n",
    "    \n",
    "    if model_path and os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        print(f\"Loaded wellness model from {model_path}\")\n",
    "    else:\n",
    "        print(\"Warning: Using untrained wellness model. Train and save model first.\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Load scaler\n",
    "    scaler = None\n",
    "    if scaler_path and os.path.exists(scaler_path):\n",
    "        with open(scaler_path, 'rb') as f:\n",
    "            scaler = pickle.load(f)\n",
    "        print(f\"Loaded scaler from {scaler_path}\")\n",
    "    else:\n",
    "        print(\"Warning: No scaler found. Using StandardScaler (will need fitting).\")\n",
    "        scaler = StandardScaler()\n",
    "    \n",
    "    return model, scaler\n",
    "\n",
    "wellness_model, wellness_scaler = load_wellness_model(\n",
    "    model_path=os.path.join(MODEL_DIR, 'wellness_model.pth'),\n",
    "    scaler_path=os.path.join(MODEL_DIR, 'wellness_scaler.pkl')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Azure Blob Storage Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Azure Blob Storage functions ready\n"
     ]
    }
   ],
   "source": [
    "# Cache for city wellness data \n",
    "_city_wellness_cache = None\n",
    "\n",
    "def load_image_from_blob(blob_name, container_name=CONTAINER_NAME_IMAGES):\n",
    "    if blob_service_client is None:\n",
    "        raise ValueError(\"Azure Blob Storage client not initialized. Check configuration.\")\n",
    "    \n",
    "    if not blob_name.startswith(\"medical_images/\"):\n",
    "        blob_name = MEDICAL_IMAGES_PREFIX + blob_name\n",
    "    \n",
    "    try:\n",
    "        blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "        blob_data = blob_client.download_blob().readall()\n",
    "        img = Image.open(io.BytesIO(blob_data)).convert(\"RGB\")\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        raise FileNotFoundError(f\"Could not load image '{blob_name}' from blob storage: {e}\")\n",
    "\n",
    "def load_city_wellness_from_parquet(parquet_blob_path=None, container_name=CONTAINER_NAME_DATA):\n",
    "    global _city_wellness_cache\n",
    "    \n",
    "    # Use cache if already loaded\n",
    "    if _city_wellness_cache is not None:\n",
    "        return _city_wellness_cache\n",
    "    \n",
    "    if blob_service_client is None:\n",
    "        raise ValueError(\"Azure Blob Storage client not initialized. Check configuration.\")\n",
    "    \n",
    "    if parquet_blob_path is None:\n",
    "        parquet_blob_path = PARQUET_BLOB_PATH\n",
    "    \n",
    "    try:\n",
    "        # Download parquet file from blob storage\n",
    "        blob_client = blob_service_client.get_blob_client(container=container_name, blob=parquet_blob_path)\n",
    "        blob_data = blob_client.download_blob().readall()\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_parquet(io.BytesIO(blob_data), engine='pyarrow')\n",
    "        except (ValueError, ImportError, AttributeError) as e:\n",
    "            if 'pandas.period' in str(e) or 'already defined' in str(e):\n",
    "                print(\"  pyarrow conflict detected, trying fastparquet...\")\n",
    "                try:\n",
    "                    df = pd.read_parquet(io.BytesIO(blob_data), engine='fastparquet')\n",
    "                except ImportError:\n",
    "                    raise ImportError(\"fastparquet not installed. Please run: !pip install fastparquet\")\n",
    "            else:\n",
    "                try:\n",
    "                    df = pd.read_parquet(io.BytesIO(blob_data), engine='fastparquet')\n",
    "                except ImportError:\n",
    "                    raise ImportError(\"Neither pyarrow nor fastparquet working. Please reinstall: !pip uninstall -y pyarrow && !pip install pyarrow\")\n",
    "        \n",
    "        if \"Obesity levels(Country)\" in df.columns:\n",
    "            df[\"Obesity levels(Country)\"] = df[\"Obesity levels(Country)\"].astype(str).str.replace(\"%\", \"\", regex=False)\n",
    "        if \"Cost of a bottle of water(City)\" in df.columns:\n",
    "            df[\"Cost of a bottle of water(City)\"] = df[\"Cost of a bottle of water(City)\"].astype(str).str.replace(\"Â£\", \"\").str.replace(\"$\", \"\").str.replace(\"â‚¬\", \"\")\n",
    "        if \"Cost of a monthly gym membership(City)\" in df.columns:\n",
    "            df[\"Cost of a monthly gym membership(City)\"] = df[\"Cost of a monthly gym membership(City)\"].astype(str).str.replace(\"Â£\", \"\").str.replace(\"$\", \"\").str.replace(\"â‚¬\", \"\")\n",
    "        \n",
    "        numeric_cols = [\n",
    "            \"Sunshine hours(City)\",\n",
    "            \"Obesity levels(Country)\",\n",
    "            \"Life expectancy(years) (Country)\",\n",
    "            \"Pollution(Index score) (City)\",\n",
    "            \"Annual avg. hours worked\",\n",
    "            \"Happiness levels(Country)\",\n",
    "            \"Outdoor activities(City)\",\n",
    "            \"Cost of a bottle of water(City)\",\n",
    "            \"Cost of a monthly gym membership(City)\"\n",
    "        ]\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].fillna(df[col].mean())\n",
    "        \n",
    "        # Cache the dataframe\n",
    "        _city_wellness_cache = df\n",
    "        print(f\" Loaded city wellness data from blob: {parquet_blob_path}\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise FileNotFoundError(f\"Could not load city wellness parquet '{parquet_blob_path}' from blob storage: {e}\")\n",
    "\n",
    "def load_city_features(city, parquet_blob_path=None):\n",
    "    \"\"\"Load city wellness features from Azure Blob Storage (parquet).\"\"\"\n",
    "    df = load_city_wellness_from_parquet(parquet_blob_path)\n",
    "    \n",
    "    city_row = df[df['City'].str.lower() == city.lower()]\n",
    "    if city_row.empty:\n",
    "        raise ValueError(f\"City '{city}' not found in city wellness data\")\n",
    "    \n",
    "    numeric_cols = [\n",
    "        \"Sunshine hours(City)\",\n",
    "        \"Obesity levels(Country)\",\n",
    "        \"Life expectancy(years) (Country)\",\n",
    "        \"Pollution(Index score) (City)\",\n",
    "        \"Annual avg. hours worked\",\n",
    "        \"Happiness levels(Country)\",\n",
    "        \"Outdoor activities(City)\",\n",
    "        \"Cost of a bottle of water(City)\",\n",
    "        \"Cost of a monthly gym membership(City)\"\n",
    "    ]\n",
    "    \n",
    "    features = []\n",
    "    for col in numeric_cols:\n",
    "        if col in city_row.columns:\n",
    "            val = city_row[col].iloc[0]\n",
    "            features.append(float(val) if pd.notna(val) else 0.0)\n",
    "        else:\n",
    "            raise ValueError(f\"Column '{col}' not found in city wellness data\")\n",
    "    \n",
    "    return np.array(features, dtype=float)\n",
    "\n",
    "print(\" Azure Blob Storage functions ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ML Score Computation Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ML score computation functions ready\n"
     ]
    }
   ],
   "source": [
    "def compute_ct_risk(image_source, from_blob=True):\n",
    "    if from_blob:\n",
    "        img = load_image_from_blob(image_source)\n",
    "    else:\n",
    "        if not os.path.exists(image_source):\n",
    "            raise FileNotFoundError(f\"Image not found: {image_source}\")\n",
    "        img = Image.open(image_source).convert(\"RGB\")\n",
    "    \n",
    "    img_tensor = ct_transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        score = ct_model(img_tensor).item()\n",
    "    \n",
    "    return float(score)\n",
    "\n",
    "def update_ct_risk_score(customer_id, image_source, from_blob=True):\n",
    "    score = compute_ct_risk(image_source, from_blob=from_blob)\n",
    "    insert_health_factor(customer_id, \"CT_RiskScore\", score)\n",
    "    return score\n",
    "\n",
    "def update_wellness_score(customer_id, city):\n",
    "    features = load_city_features(city)\n",
    "    \n",
    "    # Scale features using the same scaler from training\n",
    "    if hasattr(wellness_scaler, 'mean_') and wellness_scaler.mean_ is not None:\n",
    "        features_scaled = wellness_scaler.transform(features.reshape(1, -1))\n",
    "    else:\n",
    "        print(\"Warning: Scaler not fitted. Using raw features.\")\n",
    "        features_scaled = features.reshape(1, -1)\n",
    "    \n",
    "    features_tensor = torch.tensor(features_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        score = float(wellness_model(features_tensor).item())\n",
    "\n",
    "    insert_health_factor(customer_id, \"WellnessScore\", score)\n",
    "    return score\n",
    "\n",
    "def ensure_scores(customer_id, city=None, ct_image_blob=None, from_blob=True):\n",
    "    existing = get_health_factors(customer_id)\n",
    "    scores = {\"CT_RiskScore\": None, \"WellnessScore\": None}\n",
    "\n",
    "    for row in existing:\n",
    "        if row[\"FactorName\"] in scores:\n",
    "            scores[row[\"FactorName\"]] = row[\"FactorValue\"]\n",
    "\n",
    "    # Get city from customer if not provided\n",
    "    if city is None:\n",
    "        customer = get_customer(customer_id)\n",
    "        if customer and \"City\" in customer:\n",
    "            city = customer[\"City\"]\n",
    "        else:\n",
    "            raise ValueError(f\"City not provided and not found in customer record for ID {customer_id}\")\n",
    "\n",
    "    # Get CT image blob from database if not provided\n",
    "    if scores[\"CT_RiskScore\"] is None:\n",
    "        if ct_image_blob is None:\n",
    "            ct_image_blob = get_customer_image_blob(customer_id)\n",
    "            if ct_image_blob is None:\n",
    "                raise ValueError(f\"CT image blob not found for customer {customer_id}. Provide ct_image_blob parameter.\")\n",
    "        \n",
    "        scores[\"CT_RiskScore\"] = update_ct_risk_score(customer_id, ct_image_blob, from_blob=from_blob)\n",
    "\n",
    "    if scores[\"WellnessScore\"] is None:\n",
    "        scores[\"WellnessScore\"] = update_wellness_score(customer_id, city)\n",
    "\n",
    "    return scores\n",
    "\n",
    "def compute_premium(base, ct_score, wellness_score):\n",
    "    \"\"\"Calculate insurance premium based on ML scores.\"\"\"\n",
    "    Î± = 0.4  # CT risk weight\n",
    "    Î² = 0.6  # Wellness weight\n",
    "    premium = base * (1 + Î± * ct_score + Î² * (1 - wellness_score))\n",
    "    return float(premium)\n",
    "\n",
    "print(\" ML score computation functions ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Helper Functions - List Available Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_available_cities_from_blob(parquet_blob_path=None):\n",
    "    \"\"\"List all available cities from the parquet file in blob storage.\"\"\"\n",
    "    try:\n",
    "        df = load_city_wellness_from_parquet(parquet_blob_path)\n",
    "        if 'City' in df.columns:\n",
    "            available_cities = df['City'].tolist()\n",
    "            print(f\"Found {len(available_cities)} cities in blob storage:\")\n",
    "            print(\"\\nAvailable cities:\")\n",
    "            for i, city in enumerate(available_cities, 1):\n",
    "                print(f\"  {i}. {city}\")\n",
    "            print(f\"\\nUse any of these city names in the workflow below\")\n",
    "            print(f\"Note: City matching is case-insensitive\")\n",
    "            return available_cities\n",
    "        else:\n",
    "            print(\"Warning: 'City' column not found in parquet file\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load cities from blob storage: {e}\")\n",
    "        print(\"Make sure Azure Blob Storage is configured correctly\")\n",
    "        return []\n",
    "\n",
    "def list_available_ct_images_from_blob(container_name=CONTAINER_NAME_IMAGES, prefix=MEDICAL_IMAGES_PREFIX):\n",
    "    if blob_service_client is None:\n",
    "        print(\"Azure Blob Storage client not initialized. Cannot list images.\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        container_client = blob_service_client.get_container_client(container_name)\n",
    "        blobs = container_client.list_blobs(name_starts_with=prefix)\n",
    "        \n",
    "        image_extensions = ('.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG')\n",
    "        image_blobs = [blob.name for blob in blobs if blob.name.lower().endswith(image_extensions)]\n",
    "        \n",
    "        print(f\"Found {len(image_blobs)} CT images in blob container '{container_name}' (prefix: '{prefix}'):\")\n",
    "        if image_blobs:\n",
    "            print(\"\\nFirst 10 available image blobs:\")\n",
    "            for i, blob_name in enumerate(image_blobs[:10], 1):\n",
    "                print(f\"  {i}. {blob_name}\")\n",
    "            if len(image_blobs) > 10:\n",
    "                print(f\"  ... and {len(image_blobs) - 10} more\")\n",
    "            print(f\"\\nUse any of these blob names in the workflow below\")\n",
    "            print(f\"Note: You can use just the filename (e.g., 'covid_2020.02.25.20021568-p23-108%9.png')\")\n",
    "            print(f\"      or the full path (e.g., 'medical_images/covid_2020.02.25.20021568-p23-108%9.png')\")\n",
    "        return image_blobs\n",
    "    except Exception as e:\n",
    "        print(f\"Could not list images from blob storage: {e}\")\n",
    "        print(\"Make sure Azure Blob Storage is configured correctly\")\n",
    "        return []\n",
    "\n",
    "# Uncomment to list available data:\n",
    "# print(\"=== Available Cities ===\")\n",
    "# available_cities = list_available_cities_from_blob()\n",
    "# print(\"\\n=== Available CT Images ===\")\n",
    "# available_ct_images = list_available_ct_images_from_blob()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. End-to-End Quote Generation Workflow\n",
    "\n",
    "**Update the configuration below and run this cell to generate an insurance quote:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. User-Friendly Quote Generator\n",
    "\n",
    "**Simple interface to generate insurance quotes. Just provide the inputs below:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                    INSURANCE QUOTE GENERATOR\n",
      "======================================================================\n",
      "\n",
      " Customer: James Walker (ID: 10)\n",
      " Location: New York\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ðŸ”¬ Computing Health Risk Assessment...\n",
      "   CT Scan Risk Score:     0.7273 (72.7% risk)\n",
      "   City Wellness Score:    0.5549 (55.5% wellness)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Calculating Premium...\n",
      "   Base Premium:             $200.00\n",
      "   + CT Risk Adjustment:     +$58.18 (29.1%)\n",
      "   + Wellness Adjustment:    +$53.41 (26.7%)\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   Final Premium:            $311.59 (+55.8% change)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Creating Contract...\n",
      "   âœ“ Contract Created:        ID 25\n",
      "   âœ“ Benefit Added:           ID 23 (Health, $50,000 coverage)\n",
      "   âœ“ Premium Recorded:         $311.59/month\n",
      "\n",
      "======================================================================\n",
      "                         QUOTE SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Customer:              James Walker\n",
      "Customer ID:           10\n",
      "Location:              New York\n",
      "\n",
      "Health Assessment:\n",
      "  â€¢ CT Risk Score:      0.7273 (72.7% risk detected)\n",
      "  â€¢ Wellness Score:     0.5549 (55.5% wellness)\n",
      "\n",
      "Premium Breakdown:\n",
      "  â€¢ Base Premium:       $200.00\n",
      "  â€¢ Risk Adjustments:   +$111.59 (+55.8%)\n",
      "  â€¢ Final Premium:      $311.59/month\n",
      "\n",
      "Contract Details:\n",
      "  â€¢ Contract ID:        25\n",
      "  â€¢ Benefit ID:          23\n",
      "  â€¢ Coverage:            $50,000 (Health)\n",
      "\n",
      "======================================================================\n",
      "                    âœ“ Quote Generated Successfully!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# USER INPUT \n",
    "# ============================================================================\n",
    "CUSTOMER_ID = 10          # Customer ID from database\n",
    "BASE_PREMIUM = 200       # Base premium amount in USD\n",
    "CITY = None              # Optional: City name (will auto-retrieve from customer if None)\n",
    "CT_IMAGE_BLOB = None     # Optional: CT image blob name (will auto-retrieve from database if None)\n",
    "\n",
    "# ============================================================================\n",
    "# GENERATE QUOTE\n",
    "# ============================================================================\n",
    "\n",
    "try:\n",
    "    print(\"=\" * 70)\n",
    "    print(\" \" * 20 + \"INSURANCE QUOTE GENERATOR\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    \n",
    "    # Get customer information\n",
    "    customer = get_customer(CUSTOMER_ID)\n",
    "    if not customer:\n",
    "        raise ValueError(f\" Customer {CUSTOMER_ID} not found in database\")\n",
    "    \n",
    "    customer_name = f\"{customer.get('FirstName', 'N/A')} {customer.get('LastName', 'N/A')}\"\n",
    "    customer_city = CITY or customer.get('City', 'N/A')\n",
    "    \n",
    "    print(f\" Customer: {customer_name} (ID: {CUSTOMER_ID})\")\n",
    "    print(f\" Location: {customer_city}\")\n",
    "    print()\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Compute ML scores\n",
    "    print(\"ðŸ”¬ Computing Health Risk Assessment...\")\n",
    "    scores = ensure_scores(\n",
    "        customer_id=CUSTOMER_ID,\n",
    "        city=CITY,\n",
    "        ct_image_blob=CT_IMAGE_BLOB,\n",
    "        from_blob=True\n",
    "    )\n",
    "    \n",
    "    ct_score = scores['CT_RiskScore']\n",
    "    wellness_score = scores['WellnessScore']\n",
    "    \n",
    "    print(f\"   CT Scan Risk Score:     {ct_score:.4f} ({ct_score*100:.1f}% risk)\")\n",
    "    print(f\"   City Wellness Score:    {wellness_score:.4f} ({wellness_score*100:.1f}% wellness)\")\n",
    "    print()\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Calculate premium\n",
    "    print(\" Calculating Premium...\")\n",
    "    final_premium = compute_premium(BASE_PREMIUM, ct_score, wellness_score)\n",
    "    \n",
    "    # Calculate adjustments\n",
    "    ct_adjustment = BASE_PREMIUM * 0.4 * ct_score\n",
    "    wellness_adjustment = BASE_PREMIUM * 0.6 * (1 - wellness_score)\n",
    "    total_adjustment = ct_adjustment + wellness_adjustment\n",
    "    adjustment_percent = (total_adjustment / BASE_PREMIUM) * 100\n",
    "    \n",
    "    print(f\"   Base Premium:             ${BASE_PREMIUM:.2f}\")\n",
    "    print(f\"   + CT Risk Adjustment:     +${ct_adjustment:.2f} ({0.4 * ct_score * 100:.1f}%)\")\n",
    "    print(f\"   + Wellness Adjustment:    +${wellness_adjustment:.2f} ({0.6 * (1 - wellness_score) * 100:.1f}%)\")\n",
    "    print(f\"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "    print(f\"   Final Premium:            ${final_premium:.2f} ({adjustment_percent:+.1f}% change)\")\n",
    "    print()\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Create contract\n",
    "    print(\" Creating Contract...\")\n",
    "    contract_id = insert_contract(CUSTOMER_ID)\n",
    "    \n",
    "    contract_benefit_id = None\n",
    "    try:\n",
    "        contract_benefit_id = insert_contract_benefit(contract_id, benefit_type=\"Health\", coverage_amount=50000.00)\n",
    "        insert_contract_premium(contract_benefit_id, final_premium)\n",
    "        print(f\"   âœ“ Contract Created:        ID {contract_id}\")\n",
    "        print(f\"   âœ“ Benefit Added:           ID {contract_benefit_id} (Health, $50,000 coverage)\")\n",
    "        print(f\"   âœ“ Premium Recorded:         ${final_premium:.2f}/month\")\n",
    "    except ValueError as e:\n",
    "        print(f\" Contract created (ID: {contract_id}) but benefit/premium insertion failed\")\n",
    "        print(f\" Error: {str(e)[:100]}\")\n",
    "    \n",
    "    refresh_materialized_views()\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\" \" * 25 + \"QUOTE SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(f\"Customer:              {customer_name}\")\n",
    "    print(f\"Customer ID:           {CUSTOMER_ID}\")\n",
    "    print(f\"Location:              {customer_city}\")\n",
    "    print()\n",
    "    print(f\"Health Assessment:\")\n",
    "    print(f\"  â€¢ CT Risk Score:      {ct_score:.4f} ({ct_score*100:.1f}% risk detected)\")\n",
    "    print(f\"  â€¢ Wellness Score:     {wellness_score:.4f} ({wellness_score*100:.1f}% wellness)\")\n",
    "    print()\n",
    "    print(f\"Premium Breakdown:\")\n",
    "    print(f\"  â€¢ Base Premium:       ${BASE_PREMIUM:.2f}\")\n",
    "    print(f\"  â€¢ Risk Adjustments:   +${total_adjustment:.2f} ({adjustment_percent:+.1f}%)\")\n",
    "    print(f\"  â€¢ Final Premium:      ${final_premium:.2f}/month\")\n",
    "    print()\n",
    "    print(f\"Contract Details:\")\n",
    "    print(f\"  â€¢ Contract ID:        {contract_id}\")\n",
    "    if contract_benefit_id:\n",
    "        print(f\"  â€¢ Benefit ID:          {contract_benefit_id}\")\n",
    "        print(f\"  â€¢ Coverage:            $50,000 (Health)\")\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\" \" * 20 + \"âœ“ Quote Generated Successfully!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\" \" * 25 + \"! ERROR\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\n{str(e)}\\n\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Retraining Module\n",
    "\n",
    "**This module enables automatic retraining of ML models when new unstructured data is detected in Azure Blob Storage.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model retraining module ready\n",
      "\n",
      "To check if retraining is needed, run: trigger_model_retraining()\n",
      "After retraining, update versions with: update_model_versions()\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "MODEL_VERSION_FILE = os.path.join(MODEL_DIR, 'model_versions.json')\n",
    "\n",
    "def get_model_versions():\n",
    "    if os.path.exists(MODEL_VERSION_FILE):\n",
    "        with open(MODEL_VERSION_FILE, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {\n",
    "        'ct_model': {'last_trained': None, 'data_hash': None},\n",
    "        'wellness_model': {'last_trained': None, 'data_hash': None}\n",
    "    }\n",
    "\n",
    "def save_model_versions(versions):\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    with open(MODEL_VERSION_FILE, 'w') as f:\n",
    "        json.dump(versions, f, indent=2)\n",
    "\n",
    "def check_blob_storage_changes(container_name=CONTAINER_NAME_IMAGES, prefix=MEDICAL_IMAGES_PREFIX):\n",
    "    if blob_service_client is None:\n",
    "        return False, None, 0\n",
    "    \n",
    "    try:\n",
    "        container_client = blob_service_client.get_container_client(container_name)\n",
    "        blobs = container_client.list_blobs(name_starts_with=prefix)\n",
    "        \n",
    "        image_extensions = ('.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG')\n",
    "        image_blobs = [blob for blob in blobs if blob.name.lower().endswith(image_extensions)]\n",
    "        \n",
    "        if not image_blobs:\n",
    "            return False, None, 0\n",
    "        \n",
    "        # Get latest modification time\n",
    "        latest_time = max(blob.last_modified for blob in image_blobs)\n",
    "        image_count = len(image_blobs)\n",
    "        \n",
    "        # Check against stored version\n",
    "        versions = get_model_versions()\n",
    "        last_trained = versions.get('ct_model', {}).get('last_trained')\n",
    "        \n",
    "        if last_trained:\n",
    "            last_trained_dt = datetime.fromisoformat(last_trained.replace('Z', '+00:00'))\n",
    "            if latest_time.replace(tzinfo=latest_time.tzinfo) > last_trained_dt.replace(tzinfo=last_trained_dt.tzinfo):\n",
    "                return True, latest_time, image_count\n",
    "        \n",
    "        return False, latest_time, image_count\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking blob storage: {e}\")\n",
    "        return False, None, 0\n",
    "\n",
    "def check_parquet_changes(parquet_blob_path=None, container_name=CONTAINER_NAME_DATA):\n",
    "    if blob_service_client is None:\n",
    "        return False, None\n",
    "    \n",
    "    if parquet_blob_path is None:\n",
    "        parquet_blob_path = PARQUET_BLOB_PATH\n",
    "    \n",
    "    try:\n",
    "        blob_client = blob_service_client.get_blob_client(container=container_name, blob=parquet_blob_path)\n",
    "        blob_properties = blob_client.get_blob_properties()\n",
    "        latest_time = blob_properties.last_modified\n",
    "        \n",
    "        # Check against stored version\n",
    "        versions = get_model_versions()\n",
    "        last_trained = versions.get('wellness_model', {}).get('last_trained')\n",
    "        \n",
    "        if last_trained:\n",
    "            last_trained_dt = datetime.fromisoformat(last_trained.replace('Z', '+00:00'))\n",
    "            if latest_time.replace(tzinfo=latest_time.tzinfo) > last_trained_dt.replace(tzinfo=last_trained_dt.tzinfo):\n",
    "                return True, latest_time\n",
    "        \n",
    "        return False, latest_time\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking parquet file: {e}\")\n",
    "        return False, None\n",
    "\n",
    "def trigger_model_retraining(model_type='both'):\n",
    "    print(\"=\" * 70)\n",
    "    print(\" \" * 20 + \"MODEL RETRAINING CHECK\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    \n",
    "    versions = get_model_versions()\n",
    "    retraining_needed = False\n",
    "    \n",
    "    # Check CT model retraining\n",
    "    if model_type in ['ct', 'both']:\n",
    "        print(\"Checking CT image data...\")\n",
    "        has_changes, latest_time, image_count = check_blob_storage_changes()\n",
    "        if has_changes:\n",
    "            print(f\"    New CT images detected!\")\n",
    "            print(f\"     Latest modification: {latest_time}\")\n",
    "            print(f\"     Total images: {image_count}\")\n",
    "            print(f\"     â†’ CT model retraining recommended\")\n",
    "            retraining_needed = True\n",
    "        else:\n",
    "            print(f\"  âœ“ No new CT images detected\")\n",
    "            print(f\"     Last check: {versions.get('ct_model', {}).get('last_trained', 'Never')}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Check Wellness model retraining\n",
    "    if model_type in ['wellness', 'both']:\n",
    "        print(\"Checking city wellness data...\")\n",
    "        has_changes, latest_time = check_parquet_changes()\n",
    "        if has_changes:\n",
    "            print(f\"    City wellness parquet file updated!\")\n",
    "            print(f\"     Latest modification: {latest_time}\")\n",
    "            print(f\"     â†’ Wellness model retraining recommended\")\n",
    "            retraining_needed = True\n",
    "        else:\n",
    "            print(f\"  âœ“ City wellness data unchanged\")\n",
    "            print(f\"     Last check: {versions.get('wellness_model', {}).get('last_trained', 'Never')}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    if retraining_needed:\n",
    "        print(\"RETRAINING REQUIRED:\")\n",
    "        print(\"  1. Run mlanalysis.ipynb to retrain models with new data\")\n",
    "        print(\"  2. Models will be saved to models/ directory\")\n",
    "        print(\"  3. Update model_versions.json after retraining\")\n",
    "        print()\n",
    "        print(\"To update version tracking after retraining, run:\")\n",
    "        print(\"  update_model_versions()\")\n",
    "    else:\n",
    "        print(\"âœ“ All models are up-to-date with current data\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    return retraining_needed\n",
    "\n",
    "def update_model_versions():\n",
    "    \"\"\"Update model version tracking after retraining.\n",
    "    Call this after running mlanalysis.ipynb to retrain models.\n",
    "    \"\"\"\n",
    "    versions = get_model_versions()\n",
    "    current_time = datetime.now().isoformat()\n",
    "    \n",
    "    # Update CT model version\n",
    "    has_changes, latest_time, _ = check_blob_storage_changes()\n",
    "    if latest_time:\n",
    "        versions['ct_model'] = {\n",
    "            'last_trained': current_time,\n",
    "            'data_last_modified': latest_time.isoformat(),\n",
    "            'model_path': os.path.join(MODEL_DIR, 'ct_risk_model.pth')\n",
    "        }\n",
    "    \n",
    "    # Update Wellness model version\n",
    "    has_changes, latest_time = check_parquet_changes()\n",
    "    if latest_time:\n",
    "        versions['wellness_model'] = {\n",
    "            'last_trained': current_time,\n",
    "            'data_last_modified': latest_time.isoformat(),\n",
    "            'model_path': os.path.join(MODEL_DIR, 'wellness_model.pth'),\n",
    "            'scaler_path': os.path.join(MODEL_DIR, 'wellness_scaler.pkl')\n",
    "        }\n",
    "    \n",
    "    save_model_versions(versions)\n",
    "    print(\"âœ“ Model versions updated\")\n",
    "    print(f\"  CT Model: {versions['ct_model'].get('last_trained', 'N/A')}\")\n",
    "    print(f\"  Wellness Model: {versions['wellness_model'].get('last_trained', 'N/A')}\")\n",
    "\n",
    "print(\"âœ“ Model retraining module ready\")\n",
    "print(\"\\nTo check if retraining is needed, run: trigger_model_retraining()\")\n",
    "print(\"After retraining, update versions with: update_model_versions()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                    MODEL RETRAINING CHECK\n",
      "======================================================================\n",
      "\n",
      "Checking CT image data...\n",
      "  âœ“ No new CT images detected\n",
      "     Last check: None\n",
      "\n",
      "Checking city wellness data...\n",
      "  âœ“ City wellness data unchanged\n",
      "     Last check: None\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "âœ“ All models are up-to-date with current data\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigger_model_retraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev testing cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INSURANCE QUOTE GENERATION PIPELINE\n",
      "============================================================\n",
      "\n",
      "[STEP 1] Processing customer 1...\n",
      "  âœ“ Customer found: Ava Johnson\n",
      "\n",
      "[STEP 2] Computing ML scores...\n",
      "  âœ“ CT Risk Score: 0.7003\n",
      "  âœ“ Wellness Score: 0.5549\n",
      "\n",
      "[STEP 3] Calculating premium...\n",
      "  Base Premium: $200.00\n",
      "  Final Premium: $309.43\n",
      "\n",
      "[STEP 4] Creating contract...\n",
      "  âœ“ Contract created with ID: 26\n",
      "\n",
      "[STEP 5] Creating contract benefit...\n",
      "  âœ“ Contract benefit created with ID: 24\n",
      "\n",
      "[STEP 6] Inserting premium...\n",
      "  âœ“ Premium inserted: $309.43\n",
      "\n",
      "[STEP 7] Refreshing materialized views...\n",
      "  âœ“ Materialized views refreshed\n",
      "\n",
      "============================================================\n",
      "QUOTE SUMMARY\n",
      "============================================================\n",
      "Customer ID:        1\n",
      "Customer Name:     Ava Johnson\n",
      "City:              New York\n",
      "CT Image Blob:     Retrieved from database\n",
      "CT Risk Score:     0.7003\n",
      "Wellness Score:    0.5549\n",
      "Base Premium:      $200.00\n",
      "Final Premium:     $309.43\n",
      "Contract ID:       26\n",
      "Contract Benefit:  24\n",
      "============================================================\n",
      "âœ“ Quote generated successfully!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "customer_id = 1\n",
    "city = None \n",
    "ct_image_blob = None   \n",
    "base_premium = 200  \n",
    "\n",
    "try:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"INSURANCE QUOTE GENERATION PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"\\n[STEP 1] Processing customer {customer_id}...\")\n",
    "    customer = get_customer(customer_id)\n",
    "    if not customer:\n",
    "        raise ValueError(f\"Customer {customer_id} not found in database\")\n",
    "    \n",
    "    print(f\"  âœ“ Customer found: {customer.get('FirstName', 'N/A')} {customer.get('LastName', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\n[STEP 2] Computing ML scores...\")\n",
    "    scores = ensure_scores(\n",
    "        customer_id=customer_id, \n",
    "        city=city, \n",
    "        ct_image_blob=ct_image_blob,\n",
    "        from_blob=True  # Load from Azure Blob Storage\n",
    "    )\n",
    "    print(f\"  âœ“ CT Risk Score: {scores['CT_RiskScore']:.4f}\")\n",
    "    print(f\"  âœ“ Wellness Score: {scores['WellnessScore']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n[STEP 3] Calculating premium...\")\n",
    "    premium = compute_premium(base_premium, scores[\"CT_RiskScore\"], scores[\"WellnessScore\"])\n",
    "    print(f\"  Base Premium: ${base_premium:.2f}\")\n",
    "    print(f\"  Final Premium: ${premium:.2f}\")\n",
    "    \n",
    "    print(f\"\\n[STEP 4] Creating contract...\")\n",
    "    contract_id = insert_contract(customer_id)\n",
    "    print(f\"  âœ“ Contract created with ID: {contract_id}\")\n",
    "    \n",
    "    print(f\"\\n[STEP 5] Creating contract benefit...\")\n",
    "    contract_benefit_id = None\n",
    "    try:\n",
    "        contract_benefit_id = insert_contract_benefit(contract_id, benefit_type=\"Health\", coverage_amount=50000.00)\n",
    "        print(f\"  âœ“ Contract benefit created with ID: {contract_benefit_id}\")\n",
    "        \n",
    "        print(f\"\\n[STEP 6] Inserting premium...\")\n",
    "        insert_contract_premium(contract_benefit_id, premium)\n",
    "        print(f\"  âœ“ Premium inserted: ${premium:.2f}\")\n",
    "    except ValueError as e:\n",
    "        print(f\" {e}\")\n",
    "        print(f\" Skipping ContractBenefit and ContractPremium insertion.\")\n",
    "        print(f\"  Contract {contract_id} was created, but premium cannot be inserted without ContractBenefit.\")\n",
    "    \n",
    "    print(f\"\\n[STEP 7] Refreshing materialized views...\")\n",
    "    refresh_materialized_views()\n",
    "    print(f\"  âœ“ Materialized views refreshed\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"QUOTE SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Customer ID:        {customer_id}\")\n",
    "    print(f\"Customer Name:     {customer.get('FirstName', 'N/A')} {customer.get('LastName', 'N/A')}\")\n",
    "    print(f\"City:              {city or customer.get('City', 'N/A')}\")\n",
    "    print(f\"CT Image Blob:     {ct_image_blob or 'Retrieved from database'}\")\n",
    "    print(f\"CT Risk Score:     {scores['CT_RiskScore']:.4f}\")\n",
    "    print(f\"Wellness Score:    {scores['WellnessScore']:.4f}\")\n",
    "    print(f\"Base Premium:      ${base_premium:.2f}\")\n",
    "    print(f\"Final Premium:     ${premium:.2f}\")\n",
    "    print(f\"Contract ID:       {contract_id}\")\n",
    "    if contract_benefit_id:\n",
    "        print(f\"Contract Benefit:  {contract_benefit_id}\")\n",
    "    else:\n",
    "        print(f\"Contract Benefit:  Not created\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"âœ“ Quote generated successfully!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n !! ERROR: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
